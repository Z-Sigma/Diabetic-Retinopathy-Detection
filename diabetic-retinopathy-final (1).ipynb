{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n#from imblearn.under_sampling import RandomUnderSampler\n#from skimage.transform import rotate\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:02:41.809371Z","iopub.execute_input":"2023-07-11T09:02:41.810274Z","iopub.status.idle":"2023-07-11T09:02:42.041353Z","shell.execute_reply.started":"2023-07-11T09:02:41.810234Z","shell.execute_reply":"2023-07-11T09:02:42.040179Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:02:42.043467Z","iopub.execute_input":"2023-07-11T09:02:42.044225Z","iopub.status.idle":"2023-07-11T09:02:52.336956Z","shell.execute_reply.started":"2023-07-11T09:02:42.044187Z","shell.execute_reply":"2023-07-11T09:02:52.335853Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"img_size=256\nbatch_size=25","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:02:56.313740Z","iopub.execute_input":"2023-07-11T09:02:56.314487Z","iopub.status.idle":"2023-07-11T09:02:56.319818Z","shell.execute_reply.started":"2023-07-11T09:02:56.314448Z","shell.execute_reply":"2023-07-11T09:02:56.318129Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=5,\n    vertical_flip=True,\n    data_format=\"channels_last\",\n    validation_split=0.25,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:02:58.326796Z","iopub.execute_input":"2023-07-11T09:02:58.327187Z","iopub.status.idle":"2023-07-11T09:02:58.332622Z","shell.execute_reply.started":"2023-07-11T09:02:58.327154Z","shell.execute_reply":"2023-07-11T09:02:58.331363Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_generator = datagen.flow_from_directory(\n    r\"/kaggle/input/diabetic-retinopathy-resized-arranged\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",\n    class_mode=\"sparse\",\n    shuffle=True,\n    subset=\"training\",\n)\n\nval_generator = datagen.flow_from_directory(\n    r\"/kaggle/input/diabetic-retinopathy-resized-arranged\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",\n    class_mode=\"sparse\",\n    shuffle=True,\n    subset=\"validation\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:03:00.979102Z","iopub.execute_input":"2023-07-11T09:03:00.979502Z","iopub.status.idle":"2023-07-11T09:03:29.147499Z","shell.execute_reply.started":"2023-07-11T09:03:00.979471Z","shell.execute_reply":"2023-07-11T09:03:29.146523Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 26346 images belonging to 5 classes.\nFound 8780 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# configure gpu\ngpus = tf.config.list_physical_devices('GPU'); \nif len(gpus) == 1:\n    strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')\nelif len(gpus) > 1:\n    strategy = tf.distribute.MirroredStrategy()\nelse:\n    strategy = tf.distribute.OneDeviceStrategy(device='/cpu:0')","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:42:02.958303Z","iopub.execute_input":"2023-07-11T09:42:02.958668Z","iopub.status.idle":"2023-07-11T09:42:03.285813Z","shell.execute_reply.started":"2023-07-11T09:42:02.958637Z","shell.execute_reply":"2023-07-11T09:42:03.284839Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:42:26.743016Z","iopub.execute_input":"2023-07-11T09:42:26.743599Z","iopub.status.idle":"2023-07-11T09:42:26.750652Z","shell.execute_reply.started":"2023-07-11T09:42:26.743551Z","shell.execute_reply":"2023-07-11T09:42:26.749528Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Mixed precision enabled\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:03:29.150124Z","iopub.execute_input":"2023-07-11T09:03:29.151740Z","iopub.status.idle":"2023-07-11T09:03:29.156620Z","shell.execute_reply.started":"2023-07-11T09:03:29.151687Z","shell.execute_reply":"2023-07-11T09:03:29.155629Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"inputs = keras.Input(shape=(256, 256,1))\nx = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\nx = layers.MaxPooling2D(pool_size=(2, 2))(x)\nx = layers.Dropout(0.25)(x)\n\nx = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\nx = layers.MaxPooling2D(pool_size=(2, 2))(x)\nx = layers.Dropout(0.25)(x)\n\nx = layers.Flatten()(x)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = layers.Dropout(0.5)(x)\noutput = layers.Dense(5, activation=\"softmax\")(x)\n\nmodel1 = keras.Model(inputs=inputs, outputs=output)\n\nmodel1.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[\"accuracy\"]\n)\n\nmodel1.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:52:24.945257Z","iopub.execute_input":"2023-07-11T09:52:24.945642Z","iopub.status.idle":"2023-07-11T09:52:25.094455Z","shell.execute_reply.started":"2023-07-11T09:52:24.945609Z","shell.execute_reply":"2023-07-11T09:52:25.093701Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_3 (InputLayer)        [(None, 256, 256, 1)]     0         \n                                                                 \n conv2d_8 (Conv2D)           (None, 256, 256, 32)      320       \n                                                                 \n batch_normalization_4 (Batc  (None, 256, 256, 32)     128       \n hNormalization)                                                 \n                                                                 \n conv2d_9 (Conv2D)           (None, 256, 256, 32)      9248      \n                                                                 \n max_pooling2d_4 (MaxPooling  (None, 128, 128, 32)     0         \n 2D)                                                             \n                                                                 \n dropout_6 (Dropout)         (None, 128, 128, 32)      0         \n                                                                 \n conv2d_10 (Conv2D)          (None, 128, 128, 64)      18496     \n                                                                 \n batch_normalization_5 (Batc  (None, 128, 128, 64)     256       \n hNormalization)                                                 \n                                                                 \n conv2d_11 (Conv2D)          (None, 128, 128, 64)      36928     \n                                                                 \n max_pooling2d_5 (MaxPooling  (None, 64, 64, 64)       0         \n 2D)                                                             \n                                                                 \n dropout_7 (Dropout)         (None, 64, 64, 64)        0         \n                                                                 \n flatten_2 (Flatten)         (None, 262144)            0         \n                                                                 \n dense_4 (Dense)             (None, 512)               134218240 \n                                                                 \n dropout_8 (Dropout)         (None, 512)               0         \n                                                                 \n dense_5 (Dense)             (None, 5)                 2565      \n                                                                 \n=================================================================\nTotal params: 134,286,181\nTrainable params: 134,285,989\nNon-trainable params: 192\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model1.fit(train_generator,batch_size=25,epochs=15, verbose=2)\nmodel1.evaluate(val_generator,batch_size=25, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:52:28.937519Z","iopub.execute_input":"2023-07-11T09:52:28.937924Z","iopub.status.idle":"2023-07-11T10:57:54.949177Z","shell.execute_reply.started":"2023-07-11T09:52:28.937891Z","shell.execute_reply":"2023-07-11T10:57:54.948104Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/15\n824/824 - 263s - loss: 3.7861 - accuracy: 0.7237 - 263s/epoch - 319ms/step\nEpoch 2/15\n824/824 - 256s - loss: 0.9070 - accuracy: 0.7348 - 256s/epoch - 311ms/step\nEpoch 3/15\n824/824 - 252s - loss: 0.8872 - accuracy: 0.7346 - 252s/epoch - 306ms/step\nEpoch 4/15\n824/824 - 245s - loss: 0.8770 - accuracy: 0.7348 - 245s/epoch - 297ms/step\nEpoch 5/15\n824/824 - 247s - loss: 0.8741 - accuracy: 0.7348 - 247s/epoch - 300ms/step\nEpoch 6/15\n824/824 - 250s - loss: 0.8714 - accuracy: 0.7348 - 250s/epoch - 303ms/step\nEpoch 7/15\n824/824 - 249s - loss: 0.8697 - accuracy: 0.7347 - 249s/epoch - 303ms/step\nEpoch 8/15\n824/824 - 252s - loss: 0.8700 - accuracy: 0.7348 - 252s/epoch - 306ms/step\nEpoch 9/15\n824/824 - 254s - loss: 0.8672 - accuracy: 0.7348 - 254s/epoch - 308ms/step\nEpoch 10/15\n824/824 - 252s - loss: 0.8694 - accuracy: 0.7347 - 252s/epoch - 306ms/step\nEpoch 11/15\n824/824 - 250s - loss: 0.8695 - accuracy: 0.7348 - 250s/epoch - 304ms/step\nEpoch 12/15\n824/824 - 245s - loss: 0.8695 - accuracy: 0.7348 - 245s/epoch - 297ms/step\nEpoch 13/15\n824/824 - 248s - loss: 0.8695 - accuracy: 0.7348 - 248s/epoch - 302ms/step\nEpoch 14/15\n824/824 - 251s - loss: 0.8694 - accuracy: 0.7348 - 251s/epoch - 305ms/step\nEpoch 15/15\n824/824 - 245s - loss: 0.8690 - accuracy: 0.7348 - 245s/epoch - 297ms/step\n275/275 - 124s - loss: 0.8683 - accuracy: 0.7349 - 124s/epoch - 449ms/step\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[0.8683276772499084, 0.7348519563674927]"},"metadata":{}}]},{"cell_type":"code","source":"model1.save_weights(\"/kaggle/working/weights_model1/\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:57:59.024639Z","iopub.execute_input":"2023-07-11T10:57:59.025204Z","iopub.status.idle":"2023-07-11T10:58:11.237768Z","shell.execute_reply.started":"2023-07-11T10:57:59.025170Z","shell.execute_reply":"2023-07-11T10:58:11.236286Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model1.save(\"/kaggle/working/model1/\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:58:36.860816Z","iopub.execute_input":"2023-07-11T10:58:36.861853Z","iopub.status.idle":"2023-07-11T10:58:43.239491Z","shell.execute_reply.started":"2023-07-11T10:58:36.861805Z","shell.execute_reply":"2023-07-11T10:58:43.238481Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_generator_1 = datagen.flow_from_directory(\n    r\"/kaggle/input/diabetic-retinopathy-resized-arranged\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",\n    class_mode=\"sparse\",\n    shuffle=True,\n    subset=\"training\",\n)\n\nval_generator_1 = datagen.flow_from_directory(\n    r\"/kaggle/input/diabetic-retinopathy-resized-arranged\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",\n    class_mode=\"sparse\",\n    shuffle=True,\n    subset=\"validation\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T11:00:17.634276Z","iopub.execute_input":"2023-07-11T11:00:17.634699Z","iopub.status.idle":"2023-07-11T11:00:25.098408Z","shell.execute_reply.started":"2023-07-11T11:00:17.634667Z","shell.execute_reply":"2023-07-11T11:00:25.097501Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Found 26346 images belonging to 5 classes.\nFound 8780 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB2\n\n# Instantiate the EfficientNetB2 model (without top classification layer)\nbase_model = EfficientNetB2(include_top=False, weights='imagenet', input_shape=(260, 260, 3))\n\n# Freeze the base model's weights\nbase_model.trainable = False\n\n# Create the input layer\ninputs = tf.keras.Input(shape=(260, 260, 3))\n\n# Apply pre-processing (normalize pixel values)\npreprocessed = tf.keras.applications.efficientnet.preprocess_input(inputs)\n\n# Pass the preprocessed inputs through the EfficientNet base model\noutputs = base_model(preprocessed, training=False)\n\n# Add your own classification head\nx = layers.GlobalAveragePooling2D()(outputs)\nx = layers.Dense(256, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(5, activation='softmax')(x)  # Replace 'num_classes' with the desired number of output classes\n\n# Create the model\nnew_model = tf.keras.Model(inputs, outputs)\n\n# Compile the model\nnew_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print the model summary\nnew_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T21:26:25.200463Z","iopub.execute_input":"2023-07-15T21:26:25.201534Z","iopub.status.idle":"2023-07-15T21:26:29.584180Z","shell.execute_reply.started":"2023-07-15T21:26:25.201484Z","shell.execute_reply":"2023-07-15T21:26:29.583200Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 260, 260, 3)]     0         \n                                                                 \n efficientnetb2 (Functional)  (None, 9, 9, 1408)       7768569   \n                                                                 \n global_average_pooling2d_1   (None, 1408)             0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n dense_1 (Dense)             (None, 256)               360704    \n                                                                 \n dropout_1 (Dropout)         (None, 256)               0         \n                                                                 \n dense_2 (Dense)             (None, 5)                 1285      \n                                                                 \n=================================================================\nTotal params: 8,130,558\nTrainable params: 361,989\nNon-trainable params: 7,768,569\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"new_model.fit(train_generator_1,batch_size=25,epochs=10, verbose=2)\nnew_model.evaluate(val_generator_1,batch_size=25, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T11:01:21.170543Z","iopub.execute_input":"2023-07-11T11:01:21.171271Z","iopub.status.idle":"2023-07-11T12:24:57.783644Z","shell.execute_reply.started":"2023-07-11T11:01:21.171227Z","shell.execute_reply":"2023-07-11T12:24:57.782621Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1871: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n824/824 - 476s - loss: 0.8393 - accuracy: 0.7322 - 476s/epoch - 578ms/step\nEpoch 2/10\n824/824 - 469s - loss: 0.7781 - accuracy: 0.7408 - 469s/epoch - 569ms/step\nEpoch 3/10\n824/824 - 462s - loss: 0.7635 - accuracy: 0.7450 - 462s/epoch - 561ms/step\nEpoch 4/10\n824/824 - 461s - loss: 0.7487 - accuracy: 0.7480 - 461s/epoch - 560ms/step\nEpoch 5/10\n824/824 - 473s - loss: 0.7398 - accuracy: 0.7503 - 473s/epoch - 574ms/step\nEpoch 6/10\n824/824 - 476s - loss: 0.7320 - accuracy: 0.7523 - 476s/epoch - 577ms/step\nEpoch 7/10\n824/824 - 478s - loss: 0.7270 - accuracy: 0.7534 - 478s/epoch - 580ms/step\nEpoch 8/10\n824/824 - 475s - loss: 0.7236 - accuracy: 0.7557 - 475s/epoch - 576ms/step\nEpoch 9/10\n824/824 - 462s - loss: 0.7146 - accuracy: 0.7566 - 462s/epoch - 561ms/step\nEpoch 10/10\n824/824 - 465s - loss: 0.7134 - accuracy: 0.7580 - 465s/epoch - 565ms/step\n275/275 - 200s - loss: 0.7144 - accuracy: 0.7575 - 200s/epoch - 729ms/step\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[0.7143973708152771, 0.7575170993804932]"},"metadata":{}}]},{"cell_type":"code","source":"y_pred=new_model.predict(val_generator)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T18:51:59.325074Z","iopub.execute_input":"2023-07-09T18:51:59.325797Z","iopub.status.idle":"2023-07-09T18:52:07.721103Z","shell.execute_reply.started":"2023-07-09T18:51:59.325763Z","shell.execute_reply":"2023-07-09T18:52:07.719974Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"22/22 [==============================] - 8s 272ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-09T18:52:58.437439Z","iopub.execute_input":"2023-07-09T18:52:58.437817Z","iopub.status.idle":"2023-07-09T18:52:58.444095Z","shell.execute_reply.started":"2023-07-09T18:52:58.437788Z","shell.execute_reply":"2023-07-09T18:52:58.442707Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(686, 5)"},"metadata":{}}]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2023-07-09T18:53:25.460263Z","iopub.execute_input":"2023-07-09T18:53:25.460698Z","iopub.status.idle":"2023-07-09T18:53:25.467957Z","shell.execute_reply.started":"2023-07-09T18:53:25.460664Z","shell.execute_reply":"2023-07-09T18:53:25.466746Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"array([[0.7481307 , 0.0406514 , 0.08775906, 0.10397578, 0.01948317],\n       [0.01062862, 0.09073132, 0.34643203, 0.3544849 , 0.19772315],\n       [0.7452619 , 0.08022813, 0.0657474 , 0.08908273, 0.01967986],\n       ...,\n       [0.00122486, 0.00679002, 0.27932847, 0.2807906 , 0.43186602],\n       [0.832871  , 0.03035722, 0.06618261, 0.05446028, 0.01612891],\n       [0.97948235, 0.00568248, 0.00936423, 0.00356527, 0.00190575]],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"predictions=tf.argmax(y_pred,1)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T18:58:00.139290Z","iopub.execute_input":"2023-07-09T18:58:00.139697Z","iopub.status.idle":"2023-07-09T18:58:00.147527Z","shell.execute_reply.started":"2023-07-09T18:58:00.139666Z","shell.execute_reply":"2023-07-09T18:58:00.146549Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-07-09T18:58:06.180761Z","iopub.execute_input":"2023-07-09T18:58:06.181842Z","iopub.status.idle":"2023-07-09T18:58:06.195104Z","shell.execute_reply.started":"2023-07-09T18:58:06.181803Z","shell.execute_reply":"2023-07-09T18:58:06.193938Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(686,), dtype=int64, numpy=\narray([0, 3, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 3, 2, 2, 2,\n       0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 3, 0, 0, 2, 0, 2, 2, 0,\n       0, 2, 2, 1, 2, 0, 1, 0, 0, 0, 2, 2, 3, 0, 2, 0, 2, 2, 0, 2, 2, 2,\n       2, 2, 2, 2, 0, 0, 2, 0, 3, 0, 1, 0, 2, 0, 2, 2, 0, 2, 2, 1, 3, 0,\n       1, 3, 3, 2, 2, 0, 2, 1, 0, 0, 0, 0, 2, 1, 2, 2, 3, 2, 0, 2, 2, 0,\n       0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 1, 0, 3, 0, 2, 0, 2, 3, 2, 0, 3, 0,\n       2, 0, 2, 0, 0, 2, 0, 3, 0, 3, 0, 2, 2, 0, 3, 2, 2, 3, 2, 2, 2, 3,\n       0, 2, 1, 2, 2, 2, 2, 2, 3, 0, 2, 3, 0, 0, 2, 2, 0, 2, 3, 1, 0, 0,\n       2, 0, 2, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0,\n       1, 2, 0, 1, 0, 0, 4, 0, 3, 0, 2, 2, 2, 1, 2, 3, 2, 1, 2, 2, 0, 2,\n       3, 2, 0, 2, 3, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 3, 2, 2,\n       3, 2, 0, 3, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 3,\n       0, 2, 0, 2, 0, 3, 0, 0, 0, 3, 2, 0, 0, 3, 3, 0, 0, 1, 2, 1, 0, 0,\n       3, 2, 1, 2, 3, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 3, 0,\n       2, 3, 2, 2, 2, 0, 0, 3, 0, 3, 3, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2,\n       1, 0, 2, 2, 2, 2, 1, 0, 3, 2, 0, 3, 0, 0, 3, 3, 2, 2, 2, 3, 2, 0,\n       2, 0, 0, 2, 0, 2, 3, 0, 2, 3, 0, 2, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2,\n       1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 3,\n       2, 0, 3, 0, 0, 2, 3, 0, 2, 2, 1, 0, 3, 0, 0, 2, 0, 0, 0, 0, 2, 0,\n       2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 2, 3, 2, 0, 2, 1, 2, 3, 2, 2, 3, 3,\n       2, 4, 2, 2, 0, 3, 0, 2, 2, 2, 2, 0, 2, 2, 3, 3, 1, 0, 2, 0, 0, 2,\n       2, 0, 3, 0, 2, 2, 2, 2, 2, 2, 3, 1, 2, 0, 3, 3, 1, 2, 3, 1, 4, 0,\n       1, 2, 4, 2, 0, 0, 2, 0, 2, 3, 0, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 2,\n       0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 3, 3, 0, 0, 1,\n       3, 0, 0, 0, 0, 2, 1, 3, 3, 1, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0,\n       0, 0, 0, 0, 2, 3, 2, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 3, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 3, 0, 2, 2, 0,\n       2, 0, 0, 1, 1, 3, 0, 2, 2, 1, 0, 0, 0, 2, 1, 0, 3, 2, 2, 0, 0, 2,\n       2, 2, 2, 3, 0, 0, 2, 2, 0, 3, 0, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 1,\n       2, 2, 2, 1, 3, 2, 0, 0, 2, 2, 3, 0, 1, 0, 2, 0, 2, 0, 2, 2, 2, 2,\n       0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n       3, 4, 0, 0])>"},"metadata":{}}]},{"cell_type":"code","source":"for _ in range(5):\n    # Retrieve a batch of images and labels from the iterator\n    batch_images, batch_labels = next(val_generator_1)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T19:04:08.112001Z","iopub.execute_input":"2023-07-09T19:04:08.112971Z","iopub.status.idle":"2023-07-09T19:04:10.920378Z","shell.execute_reply.started":"2023-07-09T19:04:08.112928Z","shell.execute_reply":"2023-07-09T19:04:10.919382Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"batch_images.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-09T19:04:26.756534Z","iopub.execute_input":"2023-07-09T19:04:26.757151Z","iopub.status.idle":"2023-07-09T19:04:26.764143Z","shell.execute_reply.started":"2023-07-09T19:04:26.757115Z","shell.execute_reply":"2023-07-09T19:04:26.762860Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(32, 256, 256, 3)"},"metadata":{}}]},{"cell_type":"code","source":"batch_labels","metadata":{"execution":{"iopub.status.busy":"2023-07-09T19:05:03.063666Z","iopub.execute_input":"2023-07-09T19:05:03.064084Z","iopub.status.idle":"2023-07-09T19:05:03.071839Z","shell.execute_reply.started":"2023-07-09T19:05:03.064052Z","shell.execute_reply":"2023-07-09T19:05:03.070807Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([1., 2., 2., 0., 3., 0., 0., 2., 2., 4., 1., 0., 0., 2., 0., 0., 0.,\n       2., 0., 0., 2., 0., 1., 4., 2., 2., 1., 2., 0., 4., 2., 1.],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}